{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a5bc9b-a65e-445b-8557-36e7c26c4875",
   "metadata": {},
   "source": [
    "## Object Tracking\n",
    "-  to track objects between two images (or even in a video), you can use OpenCV’s tracking algorithms. This allows you to track moving objects, detect new or missing objects, and visualize their movement.\n",
    "- Methods for Object Tracking\n",
    "    - Simple Difference Method → Detects object position changes using cv2.absdiff().\n",
    "    - Feature Matching (ORB/SIFT) → Tracks objects by identifying key points.\n",
    "    - Deep Learning-based Tracking (YOLO + SORT or DeepSORT) → Tracks objects persistently across frames.\n",
    "    - OpenCV Built-in Trackers → Faster object tracking in videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162447e-a9d5-4e4c-8b42-3134041de87b",
   "metadata": {},
   "source": [
    "###  Method 1: Tracking with Background Subtraction\n",
    "- This method detects moving objects between two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b0fe4-5fc3-4530-a9f5-a5823f283ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def track_objects(img1_path, img2_path, output_path=\"tracked_output.png\"):\n",
    "    # Load images\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute absolute difference\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "\n",
    "    # Apply threshold\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours (Moving objects)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw rectangles around detected objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # Ignore small noise\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(img2, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "\n",
    "    # Save the tracked output\n",
    "    cv2.imwrite(output_path, img2)\n",
    "    print(f\"Object tracking completed. Output saved as {output_path}\")\n",
    "\n",
    "# Run tracking\n",
    "track_objects(\"image1.jpg\", \"image2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65a495-167b-4775-817b-15d5540b024d",
   "metadata": {},
   "source": [
    "### Method 2: Object Tracking with OpenCV Trackers (For Video)\n",
    "- If you want to track an object continuously across frames in a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc110b8-b4e7-4b7c-981d-c045fea0e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize tracker (Choose one)\n",
    "tracker = cv2.TrackerCSRT_create()  # More accurate but slower\n",
    "# tracker = cv2.TrackerKCF_create()  # Faster but less accurate\n",
    "\n",
    "# Open video\n",
    "video = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# Read first frame\n",
    "ret, frame = video.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Update tracker\n",
    "    success, bbox = tracker.update(frame)\n",
    "\n",
    "    if success:\n",
    "        x, y, w, h = [int(a) for a in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF == 27:  # Press ESC to exit\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769127d-38ef-4945-91f5-d19a5daa3535",
   "metadata": {},
   "source": [
    "### Method 3: YOLO + SORT (Best for Object Tracking in Images & Videos)\n",
    "-  If you need accurate multi-object tracking, you can use YOLO (for detection) + SORT/DeepSORT (for tracking across frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91436c7d-0869-4290-bf1e-6af965449fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from sort import Sort  # SORT tracker library\n",
    "\n",
    "# Load YOLOv8 Model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Initialize SORT tracker\n",
    "tracker = Sort()\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"image1.jpg\")\n",
    "\n",
    "# Detect objects using YOLO\n",
    "results = model(img)\n",
    "\n",
    "# Convert results to bounding boxes\n",
    "detections = []\n",
    "for r in results:\n",
    "    for box in r.boxes:\n",
    "        x1, y1, x2, y2, score, cls = box.xyxy.tolist()[0]\n",
    "        detections.append([x1, y1, x2, y2, score])\n",
    "\n",
    "# Update tracker\n",
    "tracks = tracker.update(np.array(detections))\n",
    "\n",
    "# Draw tracked objects\n",
    "for track in tracks:\n",
    "    x1, y1, x2, y2, track_id = [int(x) for x in track]\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, f\"ID {track_id}\", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"tracked_output.jpg\", img)\n",
    "print(\"Object tracking complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb1009-7205-4d63-a66b-25dae653ad12",
   "metadata": {},
   "source": [
    "###  Which Tracking Method to Use?\n",
    "### Method\tBest For\tPros\tCons\n",
    "- Simple Difference (cv2.absdiff)\tStatic image changes\tEasy, Fast\tCannot track moving objects\n",
    "- OpenCV Trackers\tTracking a single object in video\tWorks on real-time video\tNot good for multiple objects\n",
    "- YOLO + SORT\tTracking multiple objects\tBest for real-world tracking\tRequires more processing power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb777b-85b1-48ec-9b8f-ba48dfbe9c66",
   "metadata": {},
   "source": [
    "### Motion Heatmap (Tracks Object Movement Over Time)\n",
    "- A motion heatmap shows where an object has moved in a video by accumulating changes over frames.\n",
    "- If you want motion heatmaps and trajectory tracking, we can enhance object tracking by visualizing movement patterns over time.\n",
    "- Output: motion_heatmap.jpg will show where objects moved most in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0151e-f167-4e8a-8656-14d7e5ebce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# Get frame dimensions\n",
    "ret, first_frame = video.read()\n",
    "height, width = first_frame.shape[:2]\n",
    "\n",
    "# Create an empty heatmap (black image)\n",
    "heatmap = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Accumulate movement by adding pixel intensities\n",
    "    heatmap += gray.astype(np.float32)\n",
    "\n",
    "# Normalize heatmap (Scale values between 0-255)\n",
    "heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "heatmap = np.uint8(heatmap)\n",
    "\n",
    "# Apply a heatmap color mapping\n",
    "colored_heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# Save heatmap image\n",
    "cv2.imwrite(\"motion_heatmap.jpg\", colored_heatmap)\n",
    "\n",
    "print(\"Motion heatmap saved as motion_heatmap.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc936d-b01d-4ec1-b7cf-eb539199be45",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Object Trajectory Tracking (Using OpenCV & Centroid Tracking)\n",
    "-  This tracks object paths by connecting their movement across frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fd740-384b-4d7e-b636-83b56955e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open video\n",
    "video = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# Background subtractor for motion detection\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Store object trajectory points\n",
    "trajectory_points = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(gray)\n",
    "\n",
    "    # Find contours (Moving objects)\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # Filter small objects\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            centroid = (x + w // 2, y + h // 2)\n",
    "            trajectory_points.append(centroid)\n",
    "\n",
    "            # Draw bounding box and centroid\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, centroid, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Draw trajectory lines\n",
    "    for i in range(1, len(trajectory_points)):\n",
    "        cv2.line(frame, trajectory_points[i - 1], trajectory_points[i], (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Trajectory Tracking\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # Press ESC to exit\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c5535-7141-461b-b777-8d7acf19782c",
   "metadata": {},
   "source": [
    "### Advanced: Multi-Object Trajectory Tracking (YOLO + DeepSORT)\n",
    "- For complex tracking, use YOLOv8 + DeepSORT to track multiple objects and assign unique IDs.\n",
    "-  Python Code (Using YOLO + DeepSORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a184fb-6607-4575-b847-b485c13fe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import cv2\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Initialize DeepSORT tracker\n",
    "tracker = DeepSort()\n",
    "\n",
    "# Open video\n",
    "video = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect objects using YOLO\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2, score, cls = box.xyxy.tolist()[0]\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], score, int(cls)))\n",
    "\n",
    "    # Track objects\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if track.is_confirmed():\n",
    "            x, y, w, h = track.to_ltrb()\n",
    "            track_id = track.track_id\n",
    "            centroid = (int(x + w // 2), int(y + h // 2))\n",
    "\n",
    "            # Draw bounding box & trajectory\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"ID {track_id}\", (int(x), int(y) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.circle(frame, centroid, 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Multi-Object Tracking\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372a332-f5d3-4bbf-adb0-601bb3e9e51a",
   "metadata": {},
   "source": [
    "### Which Tracking Method Should You Use?\n",
    "- Method\tUse Case\tPros\tCons\n",
    "- Motion Heatmap (cv2.absdiff)\tDetect areas with high movement\tEasy to use\tDoesn’t track objects individually\n",
    "- Centroid Tracking\tTrack a single moving object\tSimple & fast\tDoesn’t work for multiple objects\n",
    "- YOLO + DeepSORT\tMulti-object tracking in real time\tBest for multiple objects\tRequires more processing power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb631c-2598-43cc-93c4-9814bcdcc057",
   "metadata": {},
   "source": [
    "### More\n",
    "-  bounding box tracking over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f2545-553a-4531-a9c1-78f640129657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
